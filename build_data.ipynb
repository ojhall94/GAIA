{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Build\n",
    "\n",
    "This notebook will go through my target selection process step by step to make sure the selections and cuts are fully transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "sns.set_palette('colorblind',10)\n",
    "sns.set_context('notebook')\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "matplotlib.rc('axes',labelsize=20) \n",
    "from astropy.table import Table\n",
    "import os\n",
    "__ddir__ = os.path.expanduser('~')+'/PhD/Gaia_Project/data/KepxDR2/'\n",
    "try:\n",
    "    os.mkdir(__ddir__+'targetlists')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using the function below to remove duplicates thoughout this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_duplicates(df,ID, sep):\n",
    "    df = df.copy(deep=True)\n",
    "    sel = df.duplicated(ID, keep=False)\n",
    "    s = df[sel]\n",
    "    for idx in range(s[ID].nunique()):\n",
    "        subset = s[s[ID] == s[ID].values[idx]]\n",
    "        lock = True  #Iterate and remove the target of largest separation\n",
    "        while lock:\n",
    "            if len(subset) > 1.:\n",
    "                drop = subset[sep].idxmax()\n",
    "                subset.drop(drop, inplace=True)\n",
    "                s.drop(drop,inplace=True)\n",
    "                df.drop(drop, inplace=True)\n",
    "            elif len(subset == 1.):\n",
    "                lock = False\n",
    "            else:\n",
    "                print('The code shouldnt be here?')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read in the [Kepler x DR2](https://gaia-kepler.fun/) catalogue (thanks Megan Bedell!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets in Kep x DR2: 195830\n"
     ]
    }
   ],
   "source": [
    "data = Table.read(__ddir__+'kepler_dr2_1arcsec.fits', format='fits')\n",
    "kdf = data.to_pandas()\n",
    "kdf.rename(columns={'kepid':'KICID',\n",
    "                    'phot_g_mean_mag':'GAIAmag',\n",
    "                    'a_g_val': 'Ag',\n",
    "                    'logg':'kic_logg'},inplace=True)\n",
    "\n",
    "#We need to construct some typical uncertainties on GAIAmag:\n",
    "kdf['e_GAIAmag'] = np.ones(len(kdf)) * 10.0e-3\n",
    "print('Targets in Kep x DR2: '+str(len(kdf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read in the [Yu et al. 2018](http://adsabs.harvard.edu/abs/2018arXiv180204455Y) catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 16094\n"
     ]
    }
   ],
   "source": [
    "sfile = '../../Catalogues/RC_catalogues/Yu+18_table1.txt'\n",
    "yu18_1 = pd.read_csv(sfile, sep='|')\n",
    "\n",
    "sfile = '../../Catalogues/RC_catalogues/Yu+18_table2.txt'\n",
    "yu18_2 = pd.read_csv(sfile, sep='|')\n",
    "yu18 = pd.merge(yu18_1, yu18_2, on='KICID',how='left')\n",
    "yu18.rename(columns={'EvoPhase':'stage',\n",
    "                    'err_x':'numax_err',\n",
    "                    'err.1_x':'dnu_err',\n",
    "                    'err_y':'Teff_err',\n",
    "                     'Fe/H':'[Fe/H]',\n",
    "                    'err.2':'[Fe/H]_err',\n",
    "                    'logg':'logg',\n",
    "                    'err.1_y':'logg_err',\n",
    "                    'err.3_y':'M_noCorrection_err',\n",
    "                    'err.4_y':'R_noCorrection_err',\n",
    "                    'err.5':'M_RGB_err',\n",
    "                    'err.6':'R_RGB_err',\n",
    "                    'err.7':'M_Clump_err',\n",
    "                    'err.8':'R_Clump_err'},inplace=True) #For consistency\n",
    "print('Targets: '+str(len(yu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Merge the KeplerxDR2 and Yu18 catalogues on KIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 16135\n"
     ]
    }
   ],
   "source": [
    "xyu18 = pd.merge(yu18, kdf, on='KICID',how='left')\n",
    "print('Targets: '+str(len(xyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Only keep duplicates with the smallest angular separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 16094\n"
     ]
    }
   ],
   "source": [
    "xyu18 = kill_duplicates(xyu18, 'KICID', 'kepler_gaia_ang_dist')\n",
    "print('Targets: '+str(len(xyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Removing any infinite parallax values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 16037\n"
     ]
    }
   ],
   "source": [
    "xyu18 = xyu18[np.isfinite(xyu18.parallax)]\n",
    "print('Targets: '+str(len(xyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Select Core Helium Burning stars only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 7673\n"
     ]
    }
   ],
   "source": [
    "rcxyu18 = xyu18[xyu18.stage==2]\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save out a list of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rcxyu18['KICID'].astype(str)\n",
    "out.to_csv(__ddir__+'/targetlists/cheb_targetlist_int.txt', index=False) #Save one without KIC in the label\n",
    "out = out.apply(lambda x: 'KIC ' + x)\n",
    "out.to_csv(__ddir__+'/targetlists/cheb_targetlist.txt',index=False) #And one with KIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Add photometry from [2MASS](http://vizier.u-strasbg.fr/cgi-bin/VizieR?-source=B/2mass) (and other useful information)\n",
    "I'll also remove any data that have negative or otherwise unphysical magnitudes or uncertainties.\n",
    "\n",
    "In addition to the 2MASS photometry, we also use the measure of magnitude in the *Gaia* *G* Band provided with the *Gaia* sample.\n",
    "\n",
    "The subsection of the 2MASS catalogue here was requested through *Vizier* on KICID for all CHeB labeled stars in this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1) Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets in 2MASS: 7811\n"
     ]
    }
   ],
   "source": [
    "twomass = pd.read_csv('../data/KepxDR2/2mass.tsv',sep='|',skiprows=48)\n",
    "twomass['KICID'] = ''\n",
    "twomass['KICID'] = twomass['_1'].apply(lambda x: x[4:]).str.strip()\n",
    "twomass = twomass[:-1] #Delete broken final column\n",
    "print('Targets in 2MASS: '+str(len(twomass)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2) Remove duplicates on angular distance to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets in 2MASS: 7672\n"
     ]
    }
   ],
   "source": [
    "twomass = kill_duplicates(twomass, 'KICID', '_r')\n",
    "print('Targets in 2MASS: '+str(len(twomass)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3) Merge with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rcxyu18['KICID'] = rcxyu18.KICID.astype(str)\n",
    "rcxyu18 = pd.merge(rcxyu18, twomass, on='KICID',how='left')\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4) Fix readin strings that should be floats, and remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 7630\n"
     ]
    }
   ],
   "source": [
    "#Kill NaN values for J band mag err (and by association J band mag)\n",
    "rcxyu18['e_Jmag'] = rcxyu18['e_Jmag'].str.strip()\n",
    "rcxyu18.drop(rcxyu18[rcxyu18.e_Jmag == ''].index.values, inplace=True)\n",
    "rcxyu18['e_Jmag'] = rcxyu18.e_Jmag.astype(float)\n",
    "\n",
    "#Kill NaN values for K band mag err (and by association K band mag)\n",
    "rcxyu18.drop(rcxyu18[~np.isfinite(rcxyu18.e_Kmag)].index.values, inplace=True)\n",
    "rcxyu18['Kmag'] = rcxyu18['Kmag'].str.strip()\n",
    "rcxyu18['Kmag'] = rcxyu18.Kmag.astype(float)\n",
    "\n",
    "#Kill NaN values forHK band mag err (and by association K band mag)\n",
    "rcxyu18['e_Hmag'] = rcxyu18['e_Hmag'].str.strip()\n",
    "rcxyu18.drop(rcxyu18[rcxyu18.e_Hmag == ''].index.values, inplace=True)\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5: Add CCD information (to later partition stars by position on sky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I request this information using the *Skygroup ID* values from MAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets with node info: 7630\n"
     ]
    }
   ],
   "source": [
    "nodes = pd.read_csv(__ddir__+'nodelist.txt',skiprows=[1])\n",
    "nodes.rename(columns={'Kepler_ID':'KICID'},inplace=True)\n",
    "nodes.KICID = nodes['KICID'].astype('str')\n",
    "print('Number of targets with node info: '+str(len(nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 7630\n"
     ]
    }
   ],
   "source": [
    "rcxyu18 = pd.merge(rcxyu18, nodes, how='left', on='KICID')\n",
    "rcxyu18['ccd'] = np.array([int((id- 1)/4) for id in rcxyu18['Skygroup_ID'].values])\n",
    "rcxyu18.head()\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6: Check the source of the Teff values in Yu+18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in Yu+18 for temperature have been sourced from the [Vizier Catalogue for Mathur+17](http://vizier.u-strasbg.fr/viz-bin/VizieR-3?-source=J/ApJS/229/30/catalog). We want to make sure that the temperatures we're using are from surveys using the same or similar temperature scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets in in Mathur+17: 7673\n"
     ]
    }
   ],
   "source": [
    "mathur17 = pd.read_csv('../data/KepxDR2/mathur_teffs.tsv',sep='|',skiprows=49)\n",
    "mathur17 = mathur17[2:].reset_index(drop=True)\n",
    "mathur17.rename(columns={'KIC':'KICID', 'Teff':'Teff_M'},inplace=True)\n",
    "mathur17['KICID'] = mathur17['KICID'].str.strip()\n",
    "mathur17 = mathur17[:-1] #Delete broken final column\n",
    "mathur17.drop(columns=['_1','_r'], inplace=True)\n",
    "print('Targets in in Mathur+17: '+str(len(mathur17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets in Mathur+17: 7673\n"
     ]
    }
   ],
   "source": [
    "mathur17 = kill_duplicates(mathur17, 'KICID', '_r')\n",
    "print('Targets in Mathur+17: '+str(len(mathur17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 7630\n"
     ]
    }
   ],
   "source": [
    "rcxyu18 = pd.merge(rcxyu18, mathur17, on='KICID',how='left')\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Get reddening & extinction from [Bayestar 17](http://argonaut.skymaps.info/) ([Green et al. 2018](http://adsabs.harvard.edu/abs/2018AAS...23135002G))\n",
    "\n",
    "We use the [Bailer-Jones estimated distance](https://arxiv.org/abs/1804.10121) to get a measure of the reddening. Any changes in reddening due to using this value over, say, using 1/$\\varpi$, falls within the priors on extinction in our model.\n",
    "\n",
    "For extinction coefficients, please see references on [omnitool.literature_values](https://github.com/ojhall94/omnitool/blob/master/omnitool/literature_values.py).\n",
    "\n",
    "**It is important to note that** Bayestar 17 does **not** report E(B-V) values. Instead, the relation holds that $E(B-V) = 0.88 \\times $ the Bayestar 17 value. Extinction coefficients reported with the Bayestar release are for **the Bayestar values specifically**, and not a value of E(B-V).\n",
    "\n",
    "For the Ag, we use the extinction reported in the *Gaia* DR2 catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnitool import spyglass\n",
    "from omnitool.literature_values import Av_coeffs\n",
    "sg = spyglass()\n",
    "sg.pass_position(rcxyu18.ra, rcxyu18.dec, frame='icrs')\n",
    "sg.pass_distance(rcxyu18.r_est)\n",
    "rcxyu18['b17'], rcxyu18['Ebv'] = sg.get_b17_ebv()\n",
    "rcxyu18['Aks'] = rcxyu18.b17 * Av_coeffs['K'].values[0]\n",
    "rcxyu18['Aj'] = rcxyu18.b17 * Av_coeffs['J'].values[0]\n",
    "rcxyu18['Ah'] = rcxyu18.b17 * Av_coeffs['H'].values[0]\n",
    "rcxyu18['H17_Ag'] = rcxyu18.Ebv * Av_coeffs['G'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Calculate (a basic) asteroseismic bolometric magnitude\n",
    "We'll do this using my omnitool package to run the asteroseismic scaling relations (no corrections to them for now).\n",
    "\n",
    "Bolometric Corrections are taken using the method by [Casagrande & Vandenburg 2018](http://adsabs.harvard.edu/abs/2018ascl.soft05022C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1) Get the asteroseismic bolometric magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating luminosity using basic asteroseismic radius\n",
      "Calculating luminosity using basic asteroseismic radius\n",
      "Calculating luminosity using basic asteroseismic radius\n"
     ]
    }
   ],
   "source": [
    "from omnitool.literature_values import Rsol, Msol, Lsol, Zsol\n",
    "from omnitool import scalings\n",
    "\n",
    "sc = scalings(rcxyu18.numax, rcxyu18.dnu, rcxyu18.Teff,\\\n",
    "                      _numax_err = rcxyu18.numax_err, _dnu_err = rcxyu18.dnu_err,\\\n",
    "                      _Teff_err = rcxyu18.Teff_err)\n",
    "rcxyu18['L'] = sc.get_luminosity()/Lsol\n",
    "rcxyu18['L_err'] = sc.get_luminosity_err()/Lsol\n",
    "rcxyu18['Mbol'] = sc.get_bolmag()\n",
    "rcxyu18['Mbol_err'] = sc.get_bolmag_err()\n",
    "rcxyu18['Z'] = Zsol * 10 ** rcxyu18['[Fe/H]'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2) Save out the data as it stands for a run through the Elsworth+17 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 7630\n"
     ]
    }
   ],
   "source": [
    "rcxyu18.to_csv('../data/KepxDR2/rcxyu18_pre_elsworth.csv',index=False)\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2.1) Save out a list of the IDs for the stars previously excluded on parallax uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rcxyu18[rcxyu18.parallax_error/rcxyu18.parallax > .35]['KICID'].astype(str)\n",
    "out = out.apply(lambda x: 'KIC ' + x)\n",
    "out.to_csv(__ddir__+'targetlists/rc_targetlist_highunc.txt',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Use Elsworth + 17 method classifications as our gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsclass = pd.read_csv('../data/KepxDR2/Elsclass-v1.txt',header=None)\n",
    "elsclass.rename(columns={0:'KICID'},inplace=True)\n",
    "elsclass.KICID = elsclass['KICID'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsclass2 = pd.read_csv('../data/KepxDR2/Elsclass-v2.txt',header=None)\n",
    "elsclass2.rename(columns={0:'KICID'},inplace=True)\n",
    "elsclass2['KICID'] = elsclass2.KICID.astype('str')\n",
    "elsclass = elsclass.append(elsclass2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 5635\n"
     ]
    }
   ],
   "source": [
    "rcxyu18 = pd.merge(elsclass, rcxyu18, on='KICID',how='left')\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these stars, there are a number that have been identified as belonging to the RC due to the seismic method, but have very large masses. We exclude these stars by truncating at 2.2 solar masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: 5570\n"
     ]
    }
   ],
   "source": [
    "rcxyu18 = rcxyu18[rcxyu18.M_Clump < 2.2]\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final count of targets in ours sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570\n"
     ]
    }
   ],
   "source": [
    "rcxyu18.to_csv('../data/KepxDR2/rcxyu18.csv',index=False)\n",
    "out = rcxyu18['KICID']\n",
    "out = out.apply(lambda x: 'KIC ' + x)\n",
    "out.to_csv('../data/KepxDR2/final_rcxyu18_targetlist.txt',index=False)\n",
    "print(str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-86e3364fd793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BC = pd.read_csv('/home/oliver/PhD/Gaia_Project/data/KepxDR2/BCs/casagrande_bcs_0.0_singular.csv')\n",
    "BC['KICID'] = BC.KICID.astype('str')\n",
    "df = pd.merge(rcxyu18, BC, on='KICID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = df.M_Clump < 2.2\n",
    "Mk = df.Mbol - df.BC_K\n",
    "plt.scatter(Mk[sel], df.Kmag[sel], c= df.M_Clump[sel])\n",
    "plt.colorbar()\n",
    "sns.distplot(Mk)\n",
    "sns.distplot(Mk[sel])\n",
    "plt.show()\n",
    "print(len(Mk[~sel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcxyu18.KICID.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets plot these on a HR diagram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets readin some tracks for the red clump from MESA\n",
    "sfile = '/home/oliver/PhD/Catalogues/Tracks/MESA_RC/m0.80.ovh0.01d.ovhe0.50s.z0.01756.y0.26627.track'\n",
    "df1 = pd.read_table(sfile, sep=r'\\s+', header=0, skiprows=5, error_bad_lines=False)\n",
    "# RC\n",
    "df1_rc = df1[(df1['center_h1'] < 1e-8) & (df1['luminosity'] > 10) & (df1['mass_conv_core'] > 0.)]\n",
    "# RGB (bearing in mind that the RGBb is probably not at the observed location)\n",
    "df1 = df1[(df1['center_h1'] < 1e-8) & (df1['luminosity'] > 10) & (df1['he_core_mass'] < 0.31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = np.arange(0.80, 1.80, 0.20)\n",
    "print(masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(rcxyu18['Z'])\n",
    "plt.axvline(np.median(rcxyu18['Z'])- .003)\n",
    "print(np.median(rcxyu18['Z'])- 0.003)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zvals = ['0.00699', '0.01108', '0.01756', '0.02783']\n",
    "yvals = ['0.25557', '0.25971', '0.26627', '0.27666']\n",
    "mi = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from omnitool.literature_values import Rsol, Msol, Lsol, Zsol\n",
    "from omnitool import scalings\n",
    "\n",
    "sc = scalings(xyu18.numax, xyu18.dnu, xyu18. Teff)\n",
    "xyu18['L'] = sc.get_luminosity()/Lsol\n",
    "\n",
    "x = np.log10(rcxyu18.Teff.values)\n",
    "y = np.log10(rcxyu18.L.values)\n",
    "#Calculate the KDE of the RC points\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "# ax.hexbin(np.log10(xyu18.Teff), np.log10(xyu18.L),gridsize=50, mincnt=1.,cmap='Greys_r')\n",
    "c = ax.hist2d(np.log10(xyu18.Teff.values), np.log10(xyu18.L.values),cmap='Greys',bins=100,norm=LogNorm(), zorder=0)\n",
    "ax.scatter(x, y, s=10, c=z, cmap='viridis',zorder=2)\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0,1,5))\n",
    "for idx, mass in enumerate(np.arange(0.8, 1.8, 0.2)):\n",
    "    mass = str(np.round(mass, 1))\n",
    "    c = colors[idx]\n",
    "    sfile = '/home/oliver/PhD/Catalogues/Tracks/MESA_RC/m'+mass+'0.ovh0.01d.ovhe0.50s.z'+zvals[mi]+'.y'+yvals[mi]+'.track'\n",
    "    df = pd.read_table(sfile, sep='\\s+', header=0, skiprows=5, error_bad_lines=False)\n",
    "    df_rc = df[(df['center_h1'] < 1e-8) & (df['luminosity'] > 10) & (df['mass_conv_core'] > 0.)][['effective_T','log_L']]\n",
    "    df_rgb = df[(df['center_h1'] < 1e-8) & (df['luminosity'] > 10) & (df['he_core_mass'] < 0.31)][['effective_T','log_L']]\n",
    "    ax.plot(np.log10(df_rgb.effective_T.values), df_rgb.log_L.values, c=c, zorder=1, linestyle='--')\n",
    "    ax.plot(np.log10(df_rc.effective_T.values), df_rc.log_L.values, c=c,zorder=3,label=str(mass) + r'$M_\\odot$')\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.legend(fancybox='True', loc='lower right', fontsize=20)\n",
    "ax.set_ylim(0.7, 2.7)\n",
    "ax.set_xlim(3.77, 3.6)\n",
    "ax.set_xlabel(r'$log_{10}(T_{\\rm eff})$(K)',fontsize=20)\n",
    "ax.set_ylabel(r'$log_{10}$(L)($L_\\odot$)',fontsize=20)\n",
    "ax.set_title('Z = '+zvals[mi]+' | Y = '+yvals[mi], fontsize=20)\n",
    "plt.savefig('/home/oliver/Dropbox/Papers/Hall+18/Figures/data.png')\n",
    "plt.savefig('/home/oliver/Dropbox/Papers/Hall+18/Figures/data.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets have a look at the distribution in the Kepler field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(rcxyu18.ra, rcxyu18.dec, c=rcxyu18.ccd, cmap='tab20b')\n",
    "ax.set_xlabel('Ra')\n",
    "ax.set_ylabel('Dec')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, lets have a look at where the $T_{\\rm eff}$ values come from..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've run *final_rcxyu18_targetlist.txt* up to the [Vizier Catalogue for Mathur+17](http://vizier.u-strasbg.fr/viz-bin/VizieR-3?-source=J/ApJS/229/30/catalog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.read_csv('../data/KepxDR2/asu_teff.tsv',sep='\\s+',skiprows=48)\n",
    "temps['KICID'] = ''\n",
    "temps['KICID'] = temps['_1'].apply(lambda x: x[4:]).str.strip()\n",
    "temps = twomass[:-1] #Delete broken final column\n",
    "print('Targets found: '+str(len(temps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = kill_duplicates(temps, 'KICID', '_r')\n",
    "print('Targets remaining '+str(len(temps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots, investigation, and other code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import barbershop\n",
    "barber = barbershop.open(rcxyu18, 'ast_MKs','Kmag')\n",
    "barber.add_client('dnu')\n",
    "barber.add_client('numax')\n",
    "barber.add_client('[Fe/H]')\n",
    "barber.add_client('M_noCorrection')\n",
    "barber.histograms_on(x=True)\n",
    "barber.show_mirror()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.distplot(rcxyu18.ast_MKs, label='Yu18 RC classified (5578 stars)')\n",
    "sns.distplot(rcxyu18_final.ast_MKs, label='Elsworth Classified (7497 stars)')\n",
    "plt.xlabel('Asteroseismic Absmag in Ks')\n",
    "plt.title('Comparing Yu+18 and Elsworth classifications',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save for future use, if necessary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets run a quick barbershop on it to see how the secondary clump and higher metallicities affect our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(elsxrcxyu18)\n",
    "elsxrcxyu18.duplicated_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcxyu18.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = np.isfinite(rcxyu18.Kmag)\n",
    "%pylab qt\n",
    "import barbershop\n",
    "barber = barbershop.open(rcxyu18[sel],'ast_MKs','Kmag')\n",
    "barber.add_client('dnu')\n",
    "barber.add_client('M')\n",
    "barber.histograms_on(x=True,y=True)\n",
    "barber.show_mirror()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdf = pd.read_csv('../data/KepxDR2/casagrande_bcs.csv')\n",
    "bcdf['KICID'] = bcdf['KICID'].astype(str)\n",
    "bcdf = kill_duplicates(bcdf, 'KICID', 'kepler_gaia_ang_dist')\n",
    "rcxyu18 = pd.merge(rcxyu18, bcdf, on='KICID',how='left')\n",
    "print('Targets: '+str(len(rcxyu18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3) Calculate the absolute magnitudes in J, H and Ks\n",
    "\n",
    "We assume the intrinsic error on the bolometric correction to be of the order of $0.02\\rm mag$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_bc = 0.04 #per cent\n",
    "rcxyu18['ast_MKs'] = rcxyu18.Mbol - rcxyu18.BC_K\n",
    "rcxyu18['ast_MH'] = rcxyu18.Mbol - rcxyu18.BC_H\n",
    "rcxyu18['ast_MJ'] = rcxyu18.Mbol - rcxyu18.BC_J\n",
    "rcxyu18['ast_MG'] = rcxyu18.Mbol - rcxyu18.BC_GAIA\n",
    "rcxyu18['ast_MKs_err'] = np.sqrt(rcxyu18.Mbol_err**2 + (rcxyu18.BC_K*err_bc)**2)\n",
    "rcxyu18['ast_MH_err'] = np.sqrt(rcxyu18.Mbol_err**2 + (rcxyu18.BC_H *err_bc)**2)\n",
    "rcxyu18['ast_MJ_err'] = np.sqrt(rcxyu18.Mbol_err**2 + (rcxyu18.BC_J *err_bc)**2)\n",
    "rcxyu18['ast_MG_err'] = np.sqrt(rcxyu18.Mbol_err**2 + (rcxyu18.BC_GAIA *err_bc)**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
