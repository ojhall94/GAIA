{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We want to do a run with no spatial covariance accounted for whatsoever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "sns.set_palette('colorblind')\n",
    "matplotlib.rc('xtick', labelsize=15)\n",
    "matplotlib.rc('ytick', labelsize=15)\n",
    "matplotlib.rc('axes',labelsize=15)\n",
    "matplotlib.rcParams['text.usetex'] = False\n",
    "\n",
    "import pandas as pd\n",
    "import pystan\n",
    "import corner\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "__outdir__ = os.path.expanduser('~')+'/PhD/Gaia_Project/Output/Parallax_Runs/Highruns/'\n",
    "__datdir__ = os.path.expanduser('~')+'/PhD/Gaia_Project/data/KepxDR2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL nocov_1388c4aa6535899f63f2c3ccb5867a25 NOW.\n"
     ]
    }
   ],
   "source": [
    "nocov = '''\n",
    "functions {\n",
    "    real bailerjones_lpdf(real r, real L){\n",
    "        return log((1/(2*L^3)) * (r*r) * exp(-r/L));\n",
    "    }\n",
    "}\n",
    "data {\n",
    "    int<lower = 0> N;\n",
    "    vector[N] m;\n",
    "    vector<lower=0>[N] m_err;\n",
    "    vector[N] oo;\n",
    "    vector<lower=0>[N] oo_err;\n",
    "    vector<lower=0>[N] RlEbv;\n",
    "\n",
    "    real oozp_init;\n",
    "    real oozp_spread;\n",
    "    real muH;\n",
    "}\n",
    "parameters {\n",
    "    //Hyperparameters\n",
    "    real mu;\n",
    "    real<lower=0.> sigma;\n",
    "    real<lower=1.> sigo;\n",
    "    real<lower=0.5,upper=1.> Q;\n",
    "    real<lower=.1, upper=4000.> L;\n",
    "    real oo_zp;\n",
    "\n",
    "    //Latent parameters\n",
    "    vector[N] M_infd_std;\n",
    "    vector[N] Ai;\n",
    "    vector<lower = 1.>[N] r_infd;\n",
    "}\n",
    "transformed parameters{\n",
    "    //Inferred and transformed parameters\n",
    "    vector[N] M_infd;\n",
    "\n",
    "    //Operations\n",
    "    for (n in 1:N){\n",
    "        M_infd[n] = mu + sigma * M_infd_std[n]; //Rescale the M fit\n",
    "    }\n",
    "}\n",
    "model {\n",
    "    //Define calculable properties\n",
    "    vector[N] m_true;\n",
    "    vector[N] oo_true;\n",
    "\n",
    "    //Hyperparameters [p(theta_rc, L)]\n",
    "    mu ~ normal(muH, 1.0); // Prior from seismo\n",
    "    sigma ~ normal(0.0, 1.0);\n",
    "    Q ~ normal(1., .25);\n",
    "    sigo ~ normal(3.0, 1.0);\n",
    "    L ~ uniform(0.1, 4000.);   // Prior on the length scale\n",
    "    oo_zp ~ normal(oozp_init, oozp_spread); // Prior on the offset (in mu as)\n",
    "\n",
    "    //Latent parameters [p(alpha_i | theta_rc, L)]\n",
    "    Ai ~ normal(RlEbv, 0.05);\n",
    "    for (n in 1:N){\n",
    "        r_infd[n] ~ bailerjones(L);\n",
    "        target += log_mix(Q,\n",
    "            normal_lpdf(M_infd_std[n] | 0., 1.),\n",
    "            normal_lpdf(M_infd_std[n] | 0., sigo));\n",
    "    }\n",
    "\n",
    "    //Calculable properties\n",
    "    for (n in 1:N){\n",
    "        m_true[n] = M_infd[n] + 5*log10(r_infd[n]) - 5 + Ai[n];\n",
    "        oo_true[n] = (1000./r_infd[n]) + (oo_zp/1000.);\n",
    "    }\n",
    "\n",
    "    //Observables [p(D | theta_rc, L, alpha)]\n",
    "    oo ~ normal(oo_true, oo_err);\n",
    "    m ~ normal(m_true, m_err); //Measurement uncertainty on magnitude\n",
    "}\n",
    "\n",
    "'''\n",
    "sm = pystan.StanModel(model_code = nocov, model_name='nocov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    sfile = __datdir__+'rcxyu18.csv'\n",
    "    df = pd.read_csv(sfile)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnitool.literature_values import hawkvals\n",
    "\n",
    "band='GAIA'\n",
    "\n",
    "rlebv = df.Ebv.values * 2.740 #As per Casagrande & Vandenberg 2018b\n",
    "\n",
    "#Correct the Gaia G mags as per Casagrande & Vandenberg 2018b\n",
    "mband = np.ones(len(df)) * df.GAIAmag.values\n",
    "sel = (mband > 6.) & (mband < 16.5)\n",
    "mband[sel] = 0.0505 + 0.9966*mband[sel]\n",
    "merr = np.ones(len(mband)) * 10.e-3 #Setting precision to 10mmag by default\n",
    "\n",
    "dat = {'N':len(df),\n",
    "        'm': mband,\n",
    "        'm_err': merr,\n",
    "        'oo': df.parallax.values,\n",
    "        'oo_err': df.parallax_error.values,\n",
    "        'RlEbv': rlebv,\n",
    "        'muH': hawkvals[band],\n",
    "        'oozp_init' : 0.,\n",
    "        'oozp_spread' : 1000.}\n",
    "\n",
    "init= {'mu': hawkvals[band],\n",
    "        'sigma': 0.1,\n",
    "        'Q': 0.95,\n",
    "        'sigo': 4.,\n",
    "        'L': 1000.,\n",
    "        'oozp':0.,\n",
    "        'r_infd':df.r_est,\n",
    "        'Ai':rlebv}\n",
    "\n",
    "pars = ['mu', 'sigma', 'Q', 'sigo', 'L', 'oo_zp']\n",
    "verbose = [r'$\\mu_{RC} (mag)$',r'$\\sigma_{RC} (mag)$',r'$Q$', r'$\\sigma_o (mag)$', r'$L (pc)$', r'$\\varpi_{zp} (\\mu as)$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runlabel = __outdir__+band+'_nocov'\n",
    "\n",
    "fit = sm.sampling(data = dat, iter = 5000, chains=4, seed = 24601,\n",
    "                    init = [init for i in range(4)])\n",
    "\n",
    "chain = np.array([fit[label] for label in pars])\n",
    "np.savetxt(runlabel+'_chains.txt', chain)\n",
    "\n",
    "pardict = {label:np.median(fit[label]) for label in pars}\n",
    "pardict.update({label+'_std':np.std(fit[label]) for label in pars})\n",
    "pardict = pd.DataFrame.from_dict(pardict, orient='index').T\n",
    "pardict.to_csv(runlabel+'_pars.csv')\n",
    "\n",
    "s = fit.summary()\n",
    "rhat = s['summary'][:,-1]\n",
    "np.savetxt(runlabel+'_rhats.txt',rhat)\n",
    "\n",
    "corner.corner(chain.T, labels=verbose,quantiles=[0.16, 0.5, 0.84],show_titles=True, title_kwargs={\"fontsize\":12})\n",
    "plt.savefig(runlabel+'_corner.png')\n",
    "plt.close()\n",
    "\n",
    "fit.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
